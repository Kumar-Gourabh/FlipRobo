{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1: Write a python program to scrape data for “Data Analyst” Job position in“Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import time\n",
    "# Opening Browsers in Incognito using Options\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--incognito')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This function opens the naukri home page and searches for 'Data Analyst' and 'Bangalore'\n",
    "\n",
    "def naukri(url):\n",
    "    driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "    # 1. first get the webpage https://www.naukri.com/\n",
    "    driver.get(url)\n",
    "    \n",
    "    # 2. Enter “Data Analyst” in “Skill,Designations,Companies” field \n",
    "    job_search=driver.find_element_by_id('qsb-keyword-sugg')\n",
    "    job_search.send_keys(\"Data Analyst\")\n",
    "    \n",
    "    # and enter “Bangalore” in “enter the location” field \n",
    "    location_search=driver.find_element_by_xpath(\"//input[@id='qsb-location-sugg']\")\n",
    "    location_search.send_keys(\"Bangalore\")\n",
    " \n",
    "    # 3. Then click the search button\n",
    "    search_buton=driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "    search_buton.click()\n",
    "    time.sleep(5)\n",
    "\n",
    "    # 4. Then scrape the data for the first 10 jobs results you get.\n",
    "    job_titles=[]\n",
    "    title_tags=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")[:10]\n",
    "    for i in title_tags:\n",
    "        job_titles.append(i.text)\n",
    "    \n",
    "    company_names=[]\n",
    "    company_tags=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")[:10]\n",
    "    for i in company_tags:\n",
    "        company_names.append(i.text)\n",
    "        \n",
    "    experience_list=[]\n",
    "    exp_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span\")[:10]\n",
    "    for i in exp_tags:\n",
    "        experience_list.append(i.text)\n",
    "        \n",
    "    salary_list=[]\n",
    "    sal_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi salary']/span\")[:10]\n",
    "    for i in sal_tags:\n",
    "        salary_list.append(i.text)\n",
    "        \n",
    "    locations_list=[]\n",
    "    loc_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span\")[:10]\n",
    "    for i in loc_tags:\n",
    "        locations_list.append(i.text)\n",
    "        \n",
    "    jobs=pd.DataFrame({})\n",
    "    jobs['job_titles']=job_titles\n",
    "    jobs['company_names']=company_names\n",
    "    jobs['locations_list']=locations_list\n",
    "    jobs['experience_list']=experience_list\n",
    "    jobs['salary_list']=salary_list\n",
    "    \n",
    "    driver.close()\n",
    "    return(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_titles</th>\n",
       "      <th>company_names</th>\n",
       "      <th>locations_list</th>\n",
       "      <th>experience_list</th>\n",
       "      <th>salary_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fresher Data Engineer / Data Scientist / Data ...</td>\n",
       "      <td>ACHYUTAS SOFT PRIVATE LIMITED</td>\n",
       "      <td>Delhi NCR, Bengaluru, Hyderabad</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "      <td>3,50,000 - 8,50,000 PA.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist/Data Analyst</td>\n",
       "      <td>CAIA-Center For Artificial Intelligence &amp; Adva...</td>\n",
       "      <td>Chennai, Pune, Bengaluru, Hyderabad</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "      <td>3,50,000 - 4,50,000 PA.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Business Data Analyst</td>\n",
       "      <td>NetApp</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>2-3 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SAS AML Data Analyst / Trainee &amp; Data Science,...</td>\n",
       "      <td>MagicBase Royal BD Pvt Ltd</td>\n",
       "      <td>Bengaluru(Whitefield)</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "      <td>50,000 - 2,00,000 PA.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hiring Data Analysts</td>\n",
       "      <td>Flipkart Internet Private Limited</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>3,00,000 - 6,00,000 PA.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hiring Data Analysts</td>\n",
       "      <td>Flipkart Internet Private Limited</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>2,50,000 - 5,50,000 PA.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>GlaxoSmithKline Pharmaceuticals Limited</td>\n",
       "      <td>Bengaluru, India</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Study Data Analyst</td>\n",
       "      <td>GlaxoSmithKline Pharmaceuticals Limited</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Cognizant Technology Solutions India Ltd</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>3-4 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Business Data Analyst | Reinsurance Domain</td>\n",
       "      <td>Mphasis Limited</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>10-15 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          job_titles  \\\n",
       "0  Fresher Data Engineer / Data Scientist / Data ...   \n",
       "1                        Data Scientist/Data Analyst   \n",
       "2                              Business Data Analyst   \n",
       "3  SAS AML Data Analyst / Trainee & Data Science,...   \n",
       "4                               Hiring Data Analysts   \n",
       "5                               Hiring Data Analysts   \n",
       "6                                       Data Analyst   \n",
       "7                                 Study Data Analyst   \n",
       "8                                       Data Analyst   \n",
       "9         Business Data Analyst | Reinsurance Domain   \n",
       "\n",
       "                                       company_names  \\\n",
       "0                      ACHYUTAS SOFT PRIVATE LIMITED   \n",
       "1  CAIA-Center For Artificial Intelligence & Adva...   \n",
       "2                                             NetApp   \n",
       "3                         MagicBase Royal BD Pvt Ltd   \n",
       "4                  Flipkart Internet Private Limited   \n",
       "5                  Flipkart Internet Private Limited   \n",
       "6            GlaxoSmithKline Pharmaceuticals Limited   \n",
       "7            GlaxoSmithKline Pharmaceuticals Limited   \n",
       "8           Cognizant Technology Solutions India Ltd   \n",
       "9                                    Mphasis Limited   \n",
       "\n",
       "                        locations_list experience_list  \\\n",
       "0      Delhi NCR, Bengaluru, Hyderabad         0-2 Yrs   \n",
       "1  Chennai, Pune, Bengaluru, Hyderabad         0-3 Yrs   \n",
       "2                            Bengaluru         2-3 Yrs   \n",
       "3                Bengaluru(Whitefield)         0-5 Yrs   \n",
       "4                            Bengaluru         2-5 Yrs   \n",
       "5                            Bengaluru         2-5 Yrs   \n",
       "6                     Bengaluru, India         3-5 Yrs   \n",
       "7                            Bengaluru         4-8 Yrs   \n",
       "8                            Bengaluru         3-4 Yrs   \n",
       "9                            Bengaluru       10-15 Yrs   \n",
       "\n",
       "               salary_list  \n",
       "0  3,50,000 - 8,50,000 PA.  \n",
       "1  3,50,000 - 4,50,000 PA.  \n",
       "2            Not disclosed  \n",
       "3    50,000 - 2,00,000 PA.  \n",
       "4  3,00,000 - 6,00,000 PA.  \n",
       "5  2,50,000 - 5,50,000 PA.  \n",
       "6            Not disclosed  \n",
       "7            Not disclosed  \n",
       "8            Not disclosed  \n",
       "9            Not disclosed  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=naukri('https://www.naukri.com/')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2. Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, full job-description. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function opens the naukri home page and searches for 'Data Analyst' and 'Bangalore'\n",
    "\n",
    "def naukri_full_desc(url):\n",
    "    driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "    # 2. Enter “Data Science” in “Skill,Designations,Companies” field\n",
    "\n",
    "    from selenium.common.exceptions import NoSuchElementException\n",
    "    driver.get(url)\n",
    "    try:\n",
    "        job_search=driver.find_element_by_id('qsb-keyword-sugg')\n",
    "        job_search.send_keys(\"Data Science\")\n",
    "    except NoSuchElementException as e:\n",
    "        print(\"Exception Raised : \", e)\n",
    "\n",
    "    # and enter “Bangalore” in “enter the location” field \n",
    "    location_search=driver.find_element_by_xpath(\"//input[@id='qsb-location-sugg']\")\n",
    "    location_search.send_keys(\"Bangalore\")\n",
    "\n",
    "    # 3. Then click the search button\n",
    "    search_buton=driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "    search_buton.click()\n",
    "    time.sleep(5)\n",
    "\n",
    "    jobs=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")[:10]\n",
    "\n",
    "    job_titles=[]\n",
    "    company_names=[]\n",
    "    exp=[]\n",
    "    sal=[]\n",
    "    desc=[]\n",
    "\n",
    "    from selenium.common.exceptions import NoSuchElementException         # Importing Exception\n",
    "\n",
    "    for i in jobs:\n",
    "        url=i.get_attribute('href')\n",
    "        driver_2=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "        driver_2.get(url)\n",
    "        try:\n",
    "            a=driver_2.find_element_by_xpath(\"//h1[@class='jd-header-title']\")\n",
    "            b=driver_2.find_element_by_xpath(\"//a[@class='pad-rt-8']\")\n",
    "            c=driver_2.find_element_by_xpath(\"//div[@class='exp']/span\")\n",
    "            d=driver_2.find_element_by_xpath(\"//div[@class='salary']/span\")\n",
    "            f=driver_2.find_elements_by_xpath(\"//div[@class='dang-inner-html']\")\n",
    "        except NoSuchElementException as e:\n",
    "            a=driver_2.find_element_by_xpath(\"//h1[@class='av-special-heading-tag ']\")\n",
    "            b=driver_2.find_element_by_xpath(\"//p[@class='cpName f14']\")\n",
    "            c=driver_2.find_element_by_xpath(\"//span[@class='slide-meta-exp pull-left']\")\n",
    "            d=driver_2.find_element_by_xpath(\"//span[@class='slide-meta-sal sal pull-left ']\")\n",
    "            f=driver_2.find_elements_by_xpath(\"//div[@class='clearboth description']\")\n",
    "\n",
    "\n",
    "        job_titles.append(a.text)\n",
    "        company_names.append(b.text)        \n",
    "        exp.append(c.text.replace('from ','').replace(' of Experience',''))\n",
    "        sal.append(d.text)\n",
    "        # Collecting full description\n",
    "        desc_content=[]\n",
    "        for j in f:\n",
    "            desc_content.append(j.text.replace('\\n',' '))\n",
    "        desc.append(desc_content)\n",
    "\n",
    "        driver_2.close()\n",
    "    \n",
    "    jobs_2=pd.DataFrame({})\n",
    "    jobs_2['job_titles']=job_titles\n",
    "    jobs_2['company_names']=company_names\n",
    "    jobs_2['Exp']=exp\n",
    "    jobs_2['Salary']=sal\n",
    "    jobs_2['Full Job Description']=desc\n",
    "    \n",
    "    driver.close()\n",
    "    return(jobs_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_titles</th>\n",
       "      <th>company_names</th>\n",
       "      <th>Exp</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Full Job Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SAS AML Data Analyst / Trainee &amp; Data Science,...</td>\n",
       "      <td>MagicBase Royal BD Pvt Ltd</td>\n",
       "      <td>0 - 5 years</td>\n",
       "      <td>₹ 50,000 - 2,00,000 P.A.</td>\n",
       "      <td>[We are looking to hire SAS Analysts/Data Scie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Freshers/Internship/Trainee - Data Science/ Ma...</td>\n",
       "      <td>IIBM</td>\n",
       "      <td>0 - 5 years</td>\n",
       "      <td>₹ 4,00,000 - 5,00,000 P.A.</td>\n",
       "      <td>[Call/whatsapp - Rohini- 8410755924 Mansi - 87...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science Engineer</td>\n",
       "      <td>Hewlett Packard Enterprise</td>\n",
       "      <td>4 - 7 years</td>\n",
       "      <td>Not Disclosed</td>\n",
       "      <td>[The HPE Software Development Engineer - Data ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Internship in Data Science, AI and Machine Lea...</td>\n",
       "      <td>ICR INDIA CERTIFICATIONS PRIVATE LIMITED</td>\n",
       "      <td>0 - 5 years</td>\n",
       "      <td>₹ 4,00,000 - 5,00,000 P.A.</td>\n",
       "      <td>[Call/whatsapp - Kriti- 7454879990  Required F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Internship in Data Science, AI and Machine Lea...</td>\n",
       "      <td>ICR INDIA CERTIFICATIONS PRIVATE LIMITED</td>\n",
       "      <td>0 - 5 years</td>\n",
       "      <td>₹ 4,00,000 - 5,00,000 P.A.</td>\n",
       "      <td>[Call/whatsapp - Ketan-9808811409, Shivani-843...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SENIOR DATA SCIENCE &amp; ANALYTICS PLATFORM ENGINEER</td>\n",
       "      <td>GlaxoSmithKline Pharmaceuticals Limited</td>\n",
       "      <td>4 to 9 year(s)</td>\n",
       "      <td>Not Disclosed by Recruiter</td>\n",
       "      <td>[Roles and Responsibilities If you are ready f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DATA SCIENCE</td>\n",
       "      <td>Capgemini Technology Services India Limited</td>\n",
       "      <td>4 to 6 year(s)</td>\n",
       "      <td>Not Disclosed by Recruiter</td>\n",
       "      <td>[Job Description Experience in Data Science Ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DATA SCIENCE</td>\n",
       "      <td>Capgemini Technology Services India Limited</td>\n",
       "      <td>6 to 9 year(s)</td>\n",
       "      <td>Not Disclosed by Recruiter</td>\n",
       "      <td>[Job Description Experience in Data Science Ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Freshers/Internship/Trainee - Data Science/ Ma...</td>\n",
       "      <td>IIBM</td>\n",
       "      <td>0 - 5 years</td>\n",
       "      <td>₹ 4,00,000 - 5,00,000 P.A.</td>\n",
       "      <td>[Call/whatsapp - Rohini- 8410755924 Mansi - 87...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Software Engineer ( Data Sciences)</td>\n",
       "      <td>Myntra Designs Pvt. Ltd.</td>\n",
       "      <td>3 - 8 years</td>\n",
       "      <td>Not Disclosed</td>\n",
       "      <td>[Roles and Responsibilities Myntra Data Scienc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          job_titles  \\\n",
       "0  SAS AML Data Analyst / Trainee & Data Science,...   \n",
       "1  Freshers/Internship/Trainee - Data Science/ Ma...   \n",
       "2                              Data Science Engineer   \n",
       "3  Internship in Data Science, AI and Machine Lea...   \n",
       "4  Internship in Data Science, AI and Machine Lea...   \n",
       "5  SENIOR DATA SCIENCE & ANALYTICS PLATFORM ENGINEER   \n",
       "6                                       DATA SCIENCE   \n",
       "7                                       DATA SCIENCE   \n",
       "8  Freshers/Internship/Trainee - Data Science/ Ma...   \n",
       "9                 Software Engineer ( Data Sciences)   \n",
       "\n",
       "                                 company_names             Exp  \\\n",
       "0                   MagicBase Royal BD Pvt Ltd     0 - 5 years   \n",
       "1                                         IIBM     0 - 5 years   \n",
       "2                   Hewlett Packard Enterprise     4 - 7 years   \n",
       "3     ICR INDIA CERTIFICATIONS PRIVATE LIMITED     0 - 5 years   \n",
       "4     ICR INDIA CERTIFICATIONS PRIVATE LIMITED     0 - 5 years   \n",
       "5      GlaxoSmithKline Pharmaceuticals Limited  4 to 9 year(s)   \n",
       "6  Capgemini Technology Services India Limited  4 to 6 year(s)   \n",
       "7  Capgemini Technology Services India Limited  6 to 9 year(s)   \n",
       "8                                         IIBM     0 - 5 years   \n",
       "9                     Myntra Designs Pvt. Ltd.     3 - 8 years   \n",
       "\n",
       "                       Salary  \\\n",
       "0    ₹ 50,000 - 2,00,000 P.A.   \n",
       "1  ₹ 4,00,000 - 5,00,000 P.A.   \n",
       "2               Not Disclosed   \n",
       "3  ₹ 4,00,000 - 5,00,000 P.A.   \n",
       "4  ₹ 4,00,000 - 5,00,000 P.A.   \n",
       "5  Not Disclosed by Recruiter   \n",
       "6  Not Disclosed by Recruiter   \n",
       "7  Not Disclosed by Recruiter   \n",
       "8  ₹ 4,00,000 - 5,00,000 P.A.   \n",
       "9               Not Disclosed   \n",
       "\n",
       "                                Full Job Description  \n",
       "0  [We are looking to hire SAS Analysts/Data Scie...  \n",
       "1  [Call/whatsapp - Rohini- 8410755924 Mansi - 87...  \n",
       "2  [The HPE Software Development Engineer - Data ...  \n",
       "3  [Call/whatsapp - Kriti- 7454879990  Required F...  \n",
       "4  [Call/whatsapp - Ketan-9808811409, Shivani-843...  \n",
       "5  [Roles and Responsibilities If you are ready f...  \n",
       "6  [Job Description Experience in Data Science Ha...  \n",
       "7  [Job Description Experience in Data Science Ha...  \n",
       "8  [Call/whatsapp - Rohini- 8410755924 Mansi - 87...  \n",
       "9  [Roles and Responsibilities Myntra Data Scienc...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=naukri_full_desc('https://www.naukri.com/')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3: In this question you have to scrape data using the filters available on the webpage as shown below:\n",
    "You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company_name, experience_required.\n",
    "The location filter to be used is “Delhi/NCR”\n",
    "The salary filter to be used is “3-6” lakhs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This function opens the naukri home page and searches for 'Data Analyst' and 'Bangalore'\n",
    "\n",
    "def naukri_advance_filters(url):\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument('--incognito')\n",
    "    driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "    # 1. first get the webpage https://www.naukri.com/\n",
    "    driver.get(url)\n",
    "    \n",
    "    # 2. Enter “Data Scientist” in “Skill,Designations,Companies” field \n",
    "    job_search=driver.find_element_by_id('qsb-keyword-sugg')\n",
    "    job_search.send_keys(\"Data Scientist\")\n",
    " \n",
    "    # 3. Then click the search button\n",
    "    search_buton=driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "    search_buton.click()\n",
    "    time.sleep(5)\n",
    "    \n",
    "    # 4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "\n",
    "    chk=driver.find_element_by_xpath(\"//div[@class='mt-8 chckBoxCont']/label[@for='chk-Delhi/NCR-cityType-']/i\")\n",
    "    chk.click()\n",
    "    time.sleep(5)\n",
    "    chk=driver.find_element_by_xpath(\"//div[@class='mt-8 chckBoxCont']/label[@for='chk-3-6 Lakhs-ctcFilter-']/i\")\n",
    "    chk.click()\n",
    "    time.sleep(5)\n",
    "\n",
    "    # 5. Then scrape the data for the first 10 jobs results you get.\n",
    "    job_titles=[]\n",
    "    title_tags=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")[:10]\n",
    "    for i in title_tags:\n",
    "        job_titles.append(i.text)\n",
    "    \n",
    "    company_names=[]\n",
    "    company_tags=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")[:10]\n",
    "    for i in company_tags:\n",
    "        company_names.append(i.text)\n",
    "        \n",
    "    experience_list=[]\n",
    "    exp_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span\")[:10]\n",
    "    for i in exp_tags:\n",
    "        experience_list.append(i.text)\n",
    "        \n",
    "    locations_list=[]\n",
    "    loc_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span\")[:10]\n",
    "    for i in loc_tags:\n",
    "        locations_list.append(i.text)\n",
    "        \n",
    "    jobs=pd.DataFrame({})\n",
    "    jobs['job_titles']=job_titles\n",
    "    jobs['company_names']=company_names\n",
    "    jobs['locations_list']=locations_list\n",
    "    jobs['experience_list']=experience_list\n",
    "    \n",
    "    driver.close()\n",
    "    return(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_titles</th>\n",
       "      <th>company_names</th>\n",
       "      <th>locations_list</th>\n",
       "      <th>experience_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fresher Data Engineer / Data Scientist / Data ...</td>\n",
       "      <td>ACHYUTAS SOFT PRIVATE LIMITED</td>\n",
       "      <td>Delhi NCR, Bengaluru, Hyderabad</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist - Python/Machine Learning</td>\n",
       "      <td>Jubna</td>\n",
       "      <td>Noida</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>PureSoftware Pvt Ltd.</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>5-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>World Wide Technology</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>NEC CORPORATION INDIA PRIVATE LTD</td>\n",
       "      <td>Delhi NCR, Noida(Sector-142 Noida)</td>\n",
       "      <td>9-14 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Excellent opportunity For Lead Data Scientist ...</td>\n",
       "      <td>NEC CORPORATION INDIA PRIVATE LTD</td>\n",
       "      <td>Delhi NCR(Sector-142 Noida), Noida</td>\n",
       "      <td>9-14 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>NEC CORPORATION INDIA PRIVATE LTD</td>\n",
       "      <td>Delhi NCR, Noida(Sector-142 Noida)</td>\n",
       "      <td>9-14 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Excellent opportunity For Lead Data Scientist ...</td>\n",
       "      <td>NEC CORPORATION INDIA PRIVATE LTD</td>\n",
       "      <td>Delhi NCR(Sector-142 Noida), Noida</td>\n",
       "      <td>9-14 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Stark Industries</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Job | Opportunity For Senior Role(Data Scienti...</td>\n",
       "      <td>BA Continuum India Pvt. Ltd</td>\n",
       "      <td>Gandhinagar, Delhi NCR, Mumbai, Gurgaon</td>\n",
       "      <td>14-17 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          job_titles  \\\n",
       "0  Fresher Data Engineer / Data Scientist / Data ...   \n",
       "1           Data Scientist - Python/Machine Learning   \n",
       "2                                     Data Scientist   \n",
       "3                                     Data Scientist   \n",
       "4                                Lead Data Scientist   \n",
       "5  Excellent opportunity For Lead Data Scientist ...   \n",
       "6                                Lead Data Scientist   \n",
       "7  Excellent opportunity For Lead Data Scientist ...   \n",
       "8                                     Data Scientist   \n",
       "9  Job | Opportunity For Senior Role(Data Scienti...   \n",
       "\n",
       "                       company_names                           locations_list  \\\n",
       "0      ACHYUTAS SOFT PRIVATE LIMITED          Delhi NCR, Bengaluru, Hyderabad   \n",
       "1                              Jubna                                    Noida   \n",
       "2              PureSoftware Pvt Ltd.                                  Gurgaon   \n",
       "3              World Wide Technology                                  Gurgaon   \n",
       "4  NEC CORPORATION INDIA PRIVATE LTD       Delhi NCR, Noida(Sector-142 Noida)   \n",
       "5  NEC CORPORATION INDIA PRIVATE LTD       Delhi NCR(Sector-142 Noida), Noida   \n",
       "6  NEC CORPORATION INDIA PRIVATE LTD       Delhi NCR, Noida(Sector-142 Noida)   \n",
       "7  NEC CORPORATION INDIA PRIVATE LTD       Delhi NCR(Sector-142 Noida), Noida   \n",
       "8                   Stark Industries                                    Delhi   \n",
       "9        BA Continuum India Pvt. Ltd  Gandhinagar, Delhi NCR, Mumbai, Gurgaon   \n",
       "\n",
       "  experience_list  \n",
       "0         0-2 Yrs  \n",
       "1         5-8 Yrs  \n",
       "2         5-9 Yrs  \n",
       "3         3-8 Yrs  \n",
       "4        9-14 Yrs  \n",
       "5        9-14 Yrs  \n",
       "6        9-14 Yrs  \n",
       "7        9-14 Yrs  \n",
       "8         3-5 Yrs  \n",
       "9       14-17 Yrs  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=naukri_advance_filters('https://www.naukri.com/')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4: Write a python program to scrape data for first 10 job results for Data scientist Designation in Noida location. You have to scrape company_name, No. of days ago when job was posted, Rating of the company. [Glassdoor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def glassdoor(url):\n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    chrome_options.add_argument(\"--incognito\")\n",
    "\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    driver.get(url)\n",
    "    \n",
    "    # Sign in Option\n",
    "    sign_in=driver.find_element_by_xpath(\"//div[@class='locked-home-sign-in']/a\")\n",
    "    url=sign_in.get_attribute('href')\n",
    "    driver_2=webdriver.Chrome(options=chrome_options)\n",
    "    driver_2.get(url)\n",
    "    time.sleep(5)\n",
    "    email=driver_2.find_element_by_id('userEmail')\n",
    "    email.send_keys('demo1994acc@gmail.com')\n",
    "    passw=driver_2.find_element_by_id('userPassword')\n",
    "    passw.send_keys('Pass@321')\n",
    "    sign_in_button=driver_2.find_element_by_xpath(\"//div/button[@class='gd-ui-button minWidthBtn css-8i7bc2']\")\n",
    "    sign_in_button.click()\n",
    "    time.sleep(5)\n",
    "    driver.close()\n",
    "    \n",
    "    # searching required fields\n",
    "    job_search=driver_2.find_element_by_id('sc.keyword')\n",
    "    job_search.send_keys('Data Scientist')\n",
    "    \n",
    "    location=driver_2.find_element_by_id('sc.location')\n",
    "    from selenium.webdriver.common.keys import Keys\n",
    "    location.send_keys(Keys.CONTROL + \"a\")\n",
    "    location.send_keys(Keys.DELETE)\n",
    "    location.send_keys('Noida')\n",
    "    \n",
    "    search_button=driver_2.find_element_by_xpath(\"//button[@class='gd-ui-button ml-std col-auto SearchStyles__newSearchButton css-iixdfr']\")\n",
    "    search_button.click()\n",
    "    time.sleep(5)\n",
    "    \n",
    "    company_name=[]\n",
    "    days_posted=[]\n",
    "    rating=[]\n",
    "    \n",
    "    # Company and days are available but for ratings need to open in new window as some are absent/missing\n",
    "    # Opening new window\n",
    "    from selenium.common.exceptions import NoSuchElementException         # Importing Exception\n",
    "    new_page=driver_2.find_elements_by_xpath(\"//div[@class='jobHeader d-flex justify-content-between align-items-start']/a\")[:10]\n",
    "    \n",
    "    for i in new_page:\n",
    "        url=i.get_attribute('href')\n",
    "        driver_3=webdriver.Chrome(options=chrome_options)\n",
    "        driver_3.get(url)\n",
    "        time.sleep(5)\n",
    "        try:\n",
    "            a=driver_3.find_element_by_xpath(\"//span[@class='css-1pmc6te e11nt52q4']\")\n",
    "            rating.append(a.text.replace('\\n★',''))\n",
    "        except NoSuchElementException as e:\n",
    "            rating.append(\"No Rating\")\n",
    "        driver_3.close() \n",
    "        \n",
    "    comps=driver_2.find_elements_by_xpath(\"//div[@class='jobHeader d-flex justify-content-between align-items-start']/a/span\")[:10]\n",
    "    for i in comps:\n",
    "        company_name.append(i.text)\n",
    "        \n",
    "    days=driver_2.find_elements_by_xpath(\"//div[@data-test='job-age']\")[:10]\n",
    "    for i in days:\n",
    "        days_posted.append(i.text)\n",
    "         \n",
    "    jobs=pd.DataFrame({})\n",
    "    jobs['company_names']=company_name\n",
    "    jobs['days_posted']=days_posted\n",
    "    jobs['rating']=rating\n",
    "    \n",
    "    driver_2.close()\n",
    "    \n",
    "    return(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_names</th>\n",
       "      <th>days_posted</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AI Engineer</td>\n",
       "      <td>13d</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ANI Calls India Private Limited</td>\n",
       "      <td>5d</td>\n",
       "      <td>No Rating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Biz2Credit Inc</td>\n",
       "      <td>30d+</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Applicate IT Solutions Pvt. Ltd.</td>\n",
       "      <td>8d</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WSD Consultant</td>\n",
       "      <td>8d</td>\n",
       "      <td>No Rating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Salasar New Age Technologies</td>\n",
       "      <td>30d+</td>\n",
       "      <td>No Rating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SearchUrCollege</td>\n",
       "      <td>30d+</td>\n",
       "      <td>No Rating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>xtLytics</td>\n",
       "      <td>30d+</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ANI Calls India Private Limited</td>\n",
       "      <td>5d</td>\n",
       "      <td>No Rating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dürr Somac GmbH</td>\n",
       "      <td>19d</td>\n",
       "      <td>No Rating</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      company_names days_posted     rating\n",
       "0                       AI Engineer         13d        3.4\n",
       "1   ANI Calls India Private Limited          5d  No Rating\n",
       "2                    Biz2Credit Inc        30d+        3.7\n",
       "3  Applicate IT Solutions Pvt. Ltd.          8d        3.3\n",
       "4                    WSD Consultant          8d  No Rating\n",
       "5      Salasar New Age Technologies        30d+  No Rating\n",
       "6                   SearchUrCollege        30d+  No Rating\n",
       "7                          xtLytics        30d+        3.0\n",
       "8   ANI Calls India Private Limited          5d  No Rating\n",
       "9                   Dürr Somac GmbH         19d  No Rating"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=glassdoor('https://www.glassdoor.co.in/index.htm')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q5: Write a python program to scrape the salary data for Data Scientist designation in Noida location. You have to scrape Company name, Number of salaries, Average salary, Min salary, Max Salary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def glassdoor_2(url):\n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    chrome_options.add_argument(\"--incognito\")\n",
    "\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    driver.get(url)\n",
    "     \n",
    "    # searching required fields\n",
    "    job_search=driver.find_element_by_id('KeywordSearch')\n",
    "    job_search.send_keys('Data Scientist')\n",
    "    \n",
    "    location=driver.find_element_by_id('LocationSearch')\n",
    "    location.clear()\n",
    "    location.send_keys('Noida')\n",
    "        \n",
    "    search_buton=driver.find_element_by_id(\"HeroSearchButton\")\n",
    "    search_buton.click()\n",
    "    time.sleep(5)\n",
    "    \n",
    "    comp=[]\n",
    "    number_of_salaries=[]\n",
    "    avg_salary=[]\n",
    "    min_salary=[]\n",
    "    max_salary=[]\n",
    "    \n",
    "    a=driver.find_elements_by_xpath(\"//div[@data-test='job-info']/p[2]\")[:10]\n",
    "    for i in a:\n",
    "        comp.append(i.text)\n",
    "        \n",
    "    a=driver.find_elements_by_xpath(\"//p[@class='css-1uyte9r css-1kuy7z7 m-0']\")[:10]\n",
    "    for i in a:\n",
    "        number_of_salaries.append(i.text.replace(' salaries',''))\n",
    "        \n",
    "    a=driver.find_elements_by_xpath(\"//div[@class='col-2 d-none d-md-flex flex-row justify-content-end']/strong\")[:10]\n",
    "    for i in a:\n",
    "        avg_salary.append(i.text)\n",
    "        \n",
    "    a=driver.find_elements_by_xpath(\"//div[@class='common__RangeBarStyle__values common__flex__justifySpaceBetween common__flex__container ']/span[1]\")[:10]\n",
    "    for i in a:\n",
    "        min_salary.append(i.text)\n",
    "        \n",
    "    a=driver.find_elements_by_xpath(\"//div[@class='common__RangeBarStyle__values common__flex__justifySpaceBetween common__flex__container ']/span[2]\")[:10]\n",
    "    for i in a:\n",
    "        max_salary.append(i.text)\n",
    "         \n",
    "    jobs=pd.DataFrame({})\n",
    "    jobs['company_names']=comp\n",
    "    jobs['number_of_salaries']=number_of_salaries\n",
    "    jobs['avg_salary']=avg_salary\n",
    "    jobs['min_salary']=min_salary\n",
    "    jobs['max_salary']=max_salary\n",
    "    \n",
    "    driver.close()\n",
    "    \n",
    "    return(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_names</th>\n",
       "      <th>number_of_salaries</th>\n",
       "      <th>avg_salary</th>\n",
       "      <th>min_salary</th>\n",
       "      <th>max_salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Delhivery</td>\n",
       "      <td>12</td>\n",
       "      <td>₹ 12,83,026</td>\n",
       "      <td>₹705K</td>\n",
       "      <td>₹11,495K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>9</td>\n",
       "      <td>₹ 11,19,272</td>\n",
       "      <td>₹571K</td>\n",
       "      <td>₹2,200K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IBM</td>\n",
       "      <td>7</td>\n",
       "      <td>₹ 7,52,445</td>\n",
       "      <td>₹580K</td>\n",
       "      <td>₹2,700K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ericsson-Worldwide</td>\n",
       "      <td>7</td>\n",
       "      <td>₹ 8,28,000</td>\n",
       "      <td>₹468K</td>\n",
       "      <td>₹1,595K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UnitedHealth Group</td>\n",
       "      <td>7</td>\n",
       "      <td>₹ 13,21,601</td>\n",
       "      <td>₹708K</td>\n",
       "      <td>₹1,557K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Analytics Vidhya</td>\n",
       "      <td>7</td>\n",
       "      <td>₹ 20,889</td>\n",
       "      <td>₹14K</td>\n",
       "      <td>₹22K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tata Consultancy Services</td>\n",
       "      <td>6</td>\n",
       "      <td>₹ 6,33,432</td>\n",
       "      <td>₹488K</td>\n",
       "      <td>₹1,000K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cognizant Technology Solutions</td>\n",
       "      <td>6</td>\n",
       "      <td>₹ 9,96,446</td>\n",
       "      <td>₹784K</td>\n",
       "      <td>₹1,250K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Valiance Solutions</td>\n",
       "      <td>6</td>\n",
       "      <td>₹ 7,71,320</td>\n",
       "      <td>₹496K</td>\n",
       "      <td>₹1,138K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Vidooly Media Tech</td>\n",
       "      <td>6</td>\n",
       "      <td>₹ 12,669</td>\n",
       "      <td>₹8K</td>\n",
       "      <td>₹20K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    company_names number_of_salaries   avg_salary min_salary  \\\n",
       "0                       Delhivery                 12  ₹ 12,83,026      ₹705K   \n",
       "1                       Accenture                  9  ₹ 11,19,272      ₹571K   \n",
       "2                             IBM                  7   ₹ 7,52,445      ₹580K   \n",
       "3              Ericsson-Worldwide                  7   ₹ 8,28,000      ₹468K   \n",
       "4              UnitedHealth Group                  7  ₹ 13,21,601      ₹708K   \n",
       "5                Analytics Vidhya                  7     ₹ 20,889       ₹14K   \n",
       "6       Tata Consultancy Services                  6   ₹ 6,33,432      ₹488K   \n",
       "7  Cognizant Technology Solutions                  6   ₹ 9,96,446      ₹784K   \n",
       "8              Valiance Solutions                  6   ₹ 7,71,320      ₹496K   \n",
       "9              Vidooly Media Tech                  6     ₹ 12,669        ₹8K   \n",
       "\n",
       "  max_salary  \n",
       "0   ₹11,495K  \n",
       "1    ₹2,200K  \n",
       "2    ₹2,700K  \n",
       "3    ₹1,595K  \n",
       "4    ₹1,557K  \n",
       "5       ₹22K  \n",
       "6    ₹1,000K  \n",
       "7    ₹1,250K  \n",
       "8    ₹1,138K  \n",
       "9       ₹20K  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=glassdoor_2('https://www.glassdoor.co.in/Salaries/index.htm')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q6 : Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. Discount %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flipkart_100(url):\n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    chrome_options.add_argument(\"--incognito\")\n",
    "\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    driver.get(url)\n",
    "    \n",
    "    #Closing Pop-up\n",
    "    close_button=driver.find_element_by_xpath(\"//button[@class='_2KpZ6l _2doB4z']\")\n",
    "    close_button.click()    \n",
    "    \n",
    "    \n",
    "    # searching required fields\n",
    "    search=driver.find_element_by_xpath(\"//div[@class='_3OO5Xc']/input\")\n",
    "    search.send_keys('sunglasses')\n",
    "    \n",
    "    search_button=driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\")\n",
    "    search_button.click()\n",
    "    time.sleep(5)\n",
    "    \n",
    "    brand=[]\n",
    "    des=[]\n",
    "    price=[]\n",
    "    discount=[]\n",
    "    \n",
    "    def extract(driver,number):\n",
    "                \n",
    "        a=driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")[:number]\n",
    "        for i in a:\n",
    "            brand.append(i.text)\n",
    "\n",
    "        a=driver.find_elements_by_xpath(\"//div[@class='_2B099V']/a[1]\")[:number]\n",
    "        for i in a:\n",
    "            des.append(i.text)\n",
    "\n",
    "        a=driver.find_elements_by_xpath(\"//div[@class='_2B099V']/a[2]/div/div[1]\")[:number]\n",
    "        for i in a:\n",
    "            price.append(i.text)\n",
    "\n",
    "        a=driver.find_elements_by_xpath(\"//div[@class='_2B099V']/a[2]/div/div[3]\")[:number]\n",
    "        for i in a:\n",
    "            discount.append(i.text)\n",
    "    \n",
    "    while(len(discount)<40):\n",
    "        extract(driver,40)\n",
    "        \n",
    "    while(len(discount)<80):\n",
    "        next=driver.find_element_by_xpath(\"//a[@class='_1LKTO3']\")\n",
    "        driver_2=webdriver.Chrome(options=chrome_options)\n",
    "        url=next.get_attribute('href')\n",
    "        driver_2.get(url)\n",
    "        extract(driver_2,40)\n",
    "    \n",
    "    while(len(discount)<100):\n",
    "        next=driver_2.find_element_by_xpath(\"//a[@class='_1LKTO3'][2]\")\n",
    "        driver_3=webdriver.Chrome(options=chrome_options)\n",
    "        url=next.get_attribute('href')\n",
    "        driver_3.get(url)\n",
    "        extract(driver_3,20)  \n",
    "    \n",
    "    jobs=pd.DataFrame({})\n",
    "    jobs['brand']=brand\n",
    "    jobs['des']=des\n",
    "    jobs['price']=price\n",
    "    jobs['discount']=discount\n",
    "    \n",
    "    driver.close()\n",
    "    driver_2.close()\n",
    "    driver_3.close()\n",
    "    \n",
    "    return(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>des</th>\n",
       "      <th>price</th>\n",
       "      <th>discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Royal Son</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (49)</td>\n",
       "      <td>₹699</td>\n",
       "      <td>65% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (88)</td>\n",
       "      <td>₹599</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FDA COLLECTION</td>\n",
       "      <td>Gradient, Mirrored, UV Protection Round, Round...</td>\n",
       "      <td>₹210</td>\n",
       "      <td>83% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FDA COLLECTION</td>\n",
       "      <td>Gradient, Mirrored, UV Protection Round, Round...</td>\n",
       "      <td>₹210</td>\n",
       "      <td>85% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Phenomenal</td>\n",
       "      <td>UV Protection, Mirrored Retro Square Sunglasse...</td>\n",
       "      <td>₹399</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Fravy</td>\n",
       "      <td>UV Protection, Others Retro Square Sunglasses ...</td>\n",
       "      <td>₹259</td>\n",
       "      <td>82% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>dannilo</td>\n",
       "      <td>Others Round Sunglasses (Free Size)</td>\n",
       "      <td>₹189</td>\n",
       "      <td>81% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Rich Club</td>\n",
       "      <td>UV Protection Round Sunglasses (50)</td>\n",
       "      <td>₹379</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Phenomenal</td>\n",
       "      <td>UV Protection, Mirrored Round Sunglasses (51)</td>\n",
       "      <td>₹379</td>\n",
       "      <td>81% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Gansta</td>\n",
       "      <td>UV Protection, Mirrored Aviator Sunglasses (55)</td>\n",
       "      <td>₹289</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             brand                                                des price  \\\n",
       "0        Royal Son         UV Protection Retro Square Sunglasses (49)  ₹699   \n",
       "1        ROYAL SON         UV Protection Retro Square Sunglasses (88)  ₹599   \n",
       "2   FDA COLLECTION  Gradient, Mirrored, UV Protection Round, Round...  ₹210   \n",
       "3   FDA COLLECTION  Gradient, Mirrored, UV Protection Round, Round...  ₹210   \n",
       "4       Phenomenal  UV Protection, Mirrored Retro Square Sunglasse...  ₹399   \n",
       "..             ...                                                ...   ...   \n",
       "95           Fravy  UV Protection, Others Retro Square Sunglasses ...  ₹259   \n",
       "96         dannilo                Others Round Sunglasses (Free Size)  ₹189   \n",
       "97       Rich Club                UV Protection Round Sunglasses (50)  ₹379   \n",
       "98      Phenomenal      UV Protection, Mirrored Round Sunglasses (51)  ₹379   \n",
       "99          Gansta    UV Protection, Mirrored Aviator Sunglasses (55)  ₹289   \n",
       "\n",
       "   discount  \n",
       "0   65% off  \n",
       "1   70% off  \n",
       "2   83% off  \n",
       "3   85% off  \n",
       "4   80% off  \n",
       "..      ...  \n",
       "95  82% off  \n",
       "96  81% off  \n",
       "97  62% off  \n",
       "98  81% off  \n",
       "99  80% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=flipkart_100('https://www.flipkart.com/')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q7: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link: \n",
    "https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flipkart_reviews(url):\n",
    "\n",
    "    driver_1 = webdriver.Chrome(options=chrome_options)\n",
    "    driver_1.get(url)\n",
    "    \n",
    "    # Opening full reviews\n",
    "    full=driver_1.find_element_by_xpath(\"//div[@class='col JOpGWq']/a\")\n",
    "    driver=webdriver.Chrome(options=chrome_options)\n",
    "    url=full.get_attribute('href')\n",
    "    driver.get(url)\n",
    "    driver_1.close()\n",
    "       \n",
    "    rating=[]\n",
    "    review_summary=[]\n",
    "    full_review=[]\n",
    "    \n",
    "    def extract(driver):\n",
    "                \n",
    "        a=driver.find_elements_by_xpath(\"//div[@class='_3LWZlK _1BLPMq']\")\n",
    "        for i in a:\n",
    "            rating.append(i.text)\n",
    "\n",
    "        a=driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\")\n",
    "        for i in a:\n",
    "            review_summary.append(i.text)\n",
    "\n",
    "        a=driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']/div/div\")\n",
    "        for i in a:\n",
    "            full_review.append(i.text)\n",
    "    \n",
    "    while(len(full_review)<10):\n",
    "        extract(driver)\n",
    "        \n",
    "    while(len(full_review)<100):\n",
    "        next=driver.find_element_by_xpath(\"//a[@class='_1LKTO3']\")\n",
    "        driver=webdriver.Chrome(options=chrome_options)\n",
    "        url=next.get_attribute('href')\n",
    "        driver.get(url)\n",
    "        extract(driver)  \n",
    "    \n",
    "    jobs=pd.DataFrame({})\n",
    "    jobs['rating']=rating\n",
    "    jobs['review_summary']=review_summary\n",
    "    jobs['full_review']=full_review\n",
    "    \n",
    "    driver.close()\n",
    "\n",
    "    return(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (100) does not match length of index (95)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-73-697c3a78d17c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflipkart_reviews\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-72-bdf6f3b174ff>\u001b[0m in \u001b[0;36mflipkart_reviews\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[0mjobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[0mjobs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'rating'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrating\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m     \u001b[0mjobs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'review_summary'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreview_summary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m     \u001b[0mjobs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'full_review'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfull_review\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3038\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3039\u001b[0m             \u001b[1;31m# set column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3040\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3114\u001b[0m         \"\"\"\n\u001b[0;32m   3115\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3116\u001b[1;33m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3117\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[1;34m(self, key, value, broadcast)\u001b[0m\n\u001b[0;32m   3762\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3763\u001b[0m             \u001b[1;31m# turn me into an ndarray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3764\u001b[1;33m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msanitize_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3765\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3766\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36msanitize_index\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    745\u001b[0m     \"\"\"\n\u001b[0;32m    746\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 747\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m    748\u001b[0m             \u001b[1;34m\"Length of values \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    749\u001b[0m             \u001b[1;34mf\"({len(data)}) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values (100) does not match length of index (95)"
     ]
    }
   ],
   "source": [
    "df=flipkart_reviews('https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q8: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field.\n",
    "You have to scrape 4 attributes of each sneaker :\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. discount %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flipkart_100_sneakers(url):\n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    chrome_options.add_argument(\"--incognito\")\n",
    "\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    driver.get(url)\n",
    "    \n",
    "    #Closing Pop-up\n",
    "    close_button=driver.find_element_by_xpath(\"//button[@class='_2KpZ6l _2doB4z']\")\n",
    "    close_button.click()    \n",
    "    \n",
    "    \n",
    "    # searching required fields\n",
    "    search=driver.find_element_by_xpath(\"//div[@class='_3OO5Xc']/input\")\n",
    "    search.send_keys('sneakers')\n",
    "    \n",
    "    search_button=driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\")\n",
    "    search_button.click()\n",
    "    time.sleep(5)\n",
    "    \n",
    "    brand=[]\n",
    "    des=[]\n",
    "    price=[]\n",
    "    discount=[]\n",
    "    \n",
    "    def extract(driver,number):\n",
    "                \n",
    "        a=driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")[:number]\n",
    "        for i in a:\n",
    "            brand.append(i.text)\n",
    "\n",
    "        a=driver.find_elements_by_xpath(\"//div[@class='_2B099V']/a[1]\")[:number]\n",
    "        for i in a:\n",
    "            des.append(i.text)\n",
    "\n",
    "        a=driver.find_elements_by_xpath(\"//div[@class='_2B099V']/a[2]/div/div[1]\")[:number]\n",
    "        for i in a:\n",
    "            price.append(i.text)\n",
    "\n",
    "        a=driver.find_elements_by_xpath(\"//div[@class='_2B099V']/a[2]/div/div[3]\")[:number]\n",
    "        for i in a:\n",
    "            discount.append(i.text)\n",
    "    \n",
    "    while(len(discount)<40):\n",
    "        extract(driver,40)\n",
    "        \n",
    "    while(len(discount)<80):\n",
    "        next=driver.find_element_by_xpath(\"//a[@class='_1LKTO3']\")\n",
    "        driver_2=webdriver.Chrome(options=chrome_options)\n",
    "        url=next.get_attribute('href')\n",
    "        driver_2.get(url)\n",
    "        extract(driver_2,40)\n",
    "    \n",
    "    while(len(discount)<100):\n",
    "        next=driver_2.find_element_by_xpath(\"//a[@class='_1LKTO3'][2]\")\n",
    "        driver_3=webdriver.Chrome(options=chrome_options)\n",
    "        url=next.get_attribute('href')\n",
    "        driver_3.get(url)\n",
    "        extract(driver_3,20)  \n",
    "    \n",
    "    jobs=pd.DataFrame({})\n",
    "    jobs['brand']=brand\n",
    "    jobs['des']=des\n",
    "    jobs['price']=price\n",
    "    jobs['discount']=discount\n",
    "    \n",
    "    driver.close()\n",
    "    driver_2.close()\n",
    "    driver_3.close()\n",
    "    \n",
    "    return(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>des</th>\n",
       "      <th>price</th>\n",
       "      <th>discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>171 Smart Tan Lace-Ups Casuals for Men Sneaker...</td>\n",
       "      <td>₹236</td>\n",
       "      <td>52% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ducati</td>\n",
       "      <td>DTSS18FT-001 Sneakers For Men</td>\n",
       "      <td>₹691</td>\n",
       "      <td>68% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Combo Pack of 4 Casual Sneakers With Sneakers ...</td>\n",
       "      <td>₹579</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>171 Smart Tan Lace-Ups Casuals for Men Sneaker...</td>\n",
       "      <td>₹273</td>\n",
       "      <td>45% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>World Wear Footwear</td>\n",
       "      <td>5011-Latest Collection Stylish Casual Loafer S...</td>\n",
       "      <td>₹240</td>\n",
       "      <td>51% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Rockfield</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹499</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Bersache</td>\n",
       "      <td>Combo(BR)-1077-349 Sneakers For Men</td>\n",
       "      <td>₹348</td>\n",
       "      <td>65% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>ESSENCE</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹499</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>TR</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹399</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Ducati</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹1,259</td>\n",
       "      <td>65% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  brand                                                des  \\\n",
       "0                Chevit  171 Smart Tan Lace-Ups Casuals for Men Sneaker...   \n",
       "1                Ducati                      DTSS18FT-001 Sneakers For Men   \n",
       "2                Chevit  Combo Pack of 4 Casual Sneakers With Sneakers ...   \n",
       "3                Chevit  171 Smart Tan Lace-Ups Casuals for Men Sneaker...   \n",
       "4   World Wear Footwear  5011-Latest Collection Stylish Casual Loafer S...   \n",
       "..                  ...                                                ...   \n",
       "95            Rockfield                                   Sneakers For Men   \n",
       "96             Bersache                Combo(BR)-1077-349 Sneakers For Men   \n",
       "97              ESSENCE                                   Sneakers For Men   \n",
       "98                   TR                                   Sneakers For Men   \n",
       "99               Ducati                                   Sneakers For Men   \n",
       "\n",
       "     price discount  \n",
       "0     ₹236  52% off  \n",
       "1     ₹691  68% off  \n",
       "2     ₹579  70% off  \n",
       "3     ₹273  45% off  \n",
       "4     ₹240  51% off  \n",
       "..     ...      ...  \n",
       "95    ₹499  50% off  \n",
       "96    ₹348  65% off  \n",
       "97    ₹499  50% off  \n",
       "98    ₹399  60% off  \n",
       "99  ₹1,259  65% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=flipkart_100_sneakers('https://www.flipkart.com/')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q9: Go to the link - https://www.myntra.com/shoes\n",
    "Set Price filter to “Rs. 6649 to Rs. 13099” [Actual Value for this search = Rs. 7649 to Rs. 15099] , Color filter to “Black”\n",
    "\n",
    "And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe description, price of the shoe as shown in the below image.\n",
    "\n",
    "Please note that applying the filter and scraping the data , everything should be done through code only and there should not be any manual step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myntra(url):\n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    chrome_options.add_argument(\"--incognito\")\n",
    "\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    driver.get(url)\n",
    "\n",
    "    # Adding required filters\n",
    "    # [Actual Value for this search = Rs. 7649 to Rs. 15099]\n",
    "    price=driver.find_element_by_xpath(\"//ul[@class='price-list']/li[2]/label/div\")\n",
    "    price.click()\n",
    "    time.sleep(5)\n",
    "    \n",
    "    color=driver.find_element_by_xpath(\"//li[@class='colour-listItem']/label/div\")\n",
    "    color.click()\n",
    "    time.sleep(5)\n",
    "    \n",
    "    brand=[]\n",
    "    des=[]\n",
    "    price=[]\n",
    "    \n",
    "    def extract_2(driver,number):\n",
    "                \n",
    "        a=driver.find_elements_by_xpath(\"//div[@class='product-productMetaInfo']/h3\")[:number]\n",
    "        for i in a:\n",
    "            brand.append(i.text)\n",
    "\n",
    "        a=driver.find_elements_by_xpath(\"//div[@class='product-productMetaInfo']/h4[1]\")[:number]\n",
    "        for i in a:\n",
    "            des.append(i.text)\n",
    "\n",
    "        a=driver.find_elements_by_xpath(\"//div[@class='product-productMetaInfo']/div/span[1]\")[:number]\n",
    "        for i in a:\n",
    "            price.append(i.text)\n",
    "\n",
    "    \n",
    "    while(len(price)<50):\n",
    "        extract_2(driver,50)\n",
    "        \n",
    "    while(len(price)<100):\n",
    "        next=driver.find_element_by_xpath(\"//li[@class='pagination-next']/a\")\n",
    "        driver_2=webdriver.Chrome(options=chrome_options)\n",
    "        url=next.get_attribute('href')\n",
    "        driver_2.get(url)\n",
    "        extract_2(driver_2,50) \n",
    "    \n",
    "    jobs=pd.DataFrame({})\n",
    "    jobs['brand']=brand\n",
    "    jobs['des']=des\n",
    "    jobs['price']=price\n",
    "    \n",
    "    driver.close()\n",
    "    driver_2.close()\n",
    "    \n",
    "    return(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>des</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADIDAS Originals</td>\n",
       "      <td>Men Superstar Sneakers</td>\n",
       "      <td>Rs. 9349Rs. 10999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Men Leather Driving Shoes</td>\n",
       "      <td>Rs. 9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men FREE RN 5.0 Running Shoes</td>\n",
       "      <td>Rs. 7995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Men Mid-Top Sneakers</td>\n",
       "      <td>Rs. 10999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men AIR ZOOM Running Shoes</td>\n",
       "      <td>Rs. 11995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Vanilla Moon</td>\n",
       "      <td>Women Perforations Flat Boots</td>\n",
       "      <td>Rs. 9990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Clarks</td>\n",
       "      <td>Men Solid Leather Sneakers</td>\n",
       "      <td>Rs. 7649Rs. 8999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Men Leather Formal Slip-Ons</td>\n",
       "      <td>Rs. 14990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Ruosh</td>\n",
       "      <td>Men Solid Leather Formal Monks</td>\n",
       "      <td>Rs. 8990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Men Leather Formal Derbys</td>\n",
       "      <td>Rs. 12990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               brand                             des              price\n",
       "0   ADIDAS Originals          Men Superstar Sneakers  Rs. 9349Rs. 10999\n",
       "1               Geox       Men Leather Driving Shoes           Rs. 9999\n",
       "2               Nike   Men FREE RN 5.0 Running Shoes           Rs. 7995\n",
       "3               Geox            Men Mid-Top Sneakers          Rs. 10999\n",
       "4               Nike      Men AIR ZOOM Running Shoes          Rs. 11995\n",
       "..               ...                             ...                ...\n",
       "95      Vanilla Moon   Women Perforations Flat Boots           Rs. 9990\n",
       "96            Clarks      Men Solid Leather Sneakers   Rs. 7649Rs. 8999\n",
       "97              Geox     Men Leather Formal Slip-Ons          Rs. 14990\n",
       "98             Ruosh  Men Solid Leather Formal Monks           Rs. 8990\n",
       "99              Geox       Men Leather Formal Derbys          Rs. 12990\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=myntra('https://www.myntra.com/shoes')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Please Note: The Price option available on the web page was \"Rs. 7649 to Rs. 15099\" after the search, so results may vary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q10: Go to webpage https://www.amazon.in/\n",
    "Enter “Laptop” in the search field and then click the search icon.\n",
    "Then set CPU Type filter to “Intel Core i7” and “Intel Core i9”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amazon(url):\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    driver.get(url)\n",
    "    \n",
    "    search_box=driver.find_element_by_id('twotabsearchtextbox')\n",
    "    search_box.send_keys('laptop')\n",
    "\n",
    "    button=driver.find_element_by_xpath(\"//div[@class='nav-right']\")\n",
    "    button.click()\n",
    "    time.sleep(5)\n",
    "\n",
    "    cpu_1=driver.find_element_by_xpath(\"//div[@id='filters']/ul/li[@aria-label='Intel Core i7']/span/a/div\")\n",
    "    cpu_1.click()\n",
    "\n",
    "    from selenium.common.exceptions import StaleElementReferenceException        # Importing Exception\n",
    "    from selenium.webdriver.support.ui import WebDriverWait\n",
    "    from selenium.webdriver.support import expected_conditions as EC\n",
    "    from selenium.webdriver.common.by import By\n",
    "\n",
    "    try:\n",
    "        cpu_2=driver.find_element_by_xpath(\"//div[@id='filters']/ul/li[@aria-label='Intel Core i9']/span/a/div\")\n",
    "        cpu_2.click()\n",
    "    except StaleElementReferenceException as e:\n",
    "        driver.get('https://www.amazon.in/')\n",
    "        search_box=driver.find_element_by_id('twotabsearchtextbox')\n",
    "        search_box.send_keys('laptop')\n",
    "        button=driver.find_element_by_xpath(\"//div[@class='nav-right']\")\n",
    "        button.click()\n",
    "        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.ID, 'filters')))\n",
    "        cpu_2=driver.find_element_by_xpath(\"//div[@id='filters']/ul/li[@aria-label='Intel Core i9']/span/a/div\")\n",
    "        cpu_2.click()\n",
    "    \n",
    "    title=[]\n",
    "\n",
    "    a=driver.find_elements_by_xpath(\"//span[@class='a-size-medium a-color-base a-text-normal']\")[:10]\n",
    "    for i in a:\n",
    "        title.append(i.text)\n",
    "\n",
    "    rating=[]\n",
    "\n",
    "    a=driver.find_elements_by_xpath(\"//div[@class='a-row a-size-small']/span/span/a/i/span\")[:10]\n",
    "    for i in a:\n",
    "        rating.append(i.text)\n",
    "\n",
    "    price=[]\n",
    "\n",
    "    a=driver.find_elements_by_xpath(\"//span[@class='a-price-whole']\")[:10]\n",
    "    for i in a:\n",
    "        price.append(i.text)\n",
    "        \n",
    "    jobs=pd.DataFrame({})\n",
    "    jobs['title']=title\n",
    "    jobs['rating']=rating\n",
    "    jobs['price']=price\n",
    "    \n",
    "    driver.close()\n",
    "    return(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>rating</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lenovo ThinkPad E14 Intel Core i7 10th Gen14-i...</td>\n",
       "      <td></td>\n",
       "      <td>84,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASUS ZenBook 14 (2020) Intel Core i7-1165G7 11...</td>\n",
       "      <td></td>\n",
       "      <td>95,840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Renewed) Dell Inspiron 3567 Laptop Core i3-7t...</td>\n",
       "      <td></td>\n",
       "      <td>29,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Renewed) Lenovo ThinkPad High Performance 12....</td>\n",
       "      <td></td>\n",
       "      <td>34,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASUS TUF Gaming F15 Laptop 15.6\" FHD Intel Cor...</td>\n",
       "      <td></td>\n",
       "      <td>73,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(Renewed) HP EliteBook FOLIO 9480M Laptop (Cor...</td>\n",
       "      <td></td>\n",
       "      <td>24,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Asus ROG Strix G15 Core i7 10th Gen - (8 GB/51...</td>\n",
       "      <td></td>\n",
       "      <td>84,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HP Pavilion x360 Touchscreen 2-in-1 FHD 14-inc...</td>\n",
       "      <td></td>\n",
       "      <td>74,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ASUS TUF Gaming F15, 15.6\" FHD 144Hz, Intel Co...</td>\n",
       "      <td></td>\n",
       "      <td>94,499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HP Pavilion x360 Core i7 8th Gen 14-inch Touch...</td>\n",
       "      <td></td>\n",
       "      <td>82,990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title rating   price\n",
       "0  Lenovo ThinkPad E14 Intel Core i7 10th Gen14-i...         84,990\n",
       "1  ASUS ZenBook 14 (2020) Intel Core i7-1165G7 11...         95,840\n",
       "2  (Renewed) Dell Inspiron 3567 Laptop Core i3-7t...         29,990\n",
       "3  (Renewed) Lenovo ThinkPad High Performance 12....         34,999\n",
       "4  ASUS TUF Gaming F15 Laptop 15.6\" FHD Intel Cor...         73,990\n",
       "5  (Renewed) HP EliteBook FOLIO 9480M Laptop (Cor...         24,490\n",
       "6  Asus ROG Strix G15 Core i7 10th Gen - (8 GB/51...         84,990\n",
       "7  HP Pavilion x360 Touchscreen 2-in-1 FHD 14-inc...         74,990\n",
       "8  ASUS TUF Gaming F15, 15.6\" FHD 144Hz, Intel Co...         94,499\n",
       "9  HP Pavilion x360 Core i7 8th Gen 14-inch Touch...         82,990"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=amazon('https://www.amazon.in/')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
